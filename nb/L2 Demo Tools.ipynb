{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.messages import (\n    HumanMessage, \n    SystemMessage, \n    ToolMessage\n)\nfrom langchain.tools import tool\nfrom langchain_core.output_parsers.openai_tools import parse_tool_calls\nfrom dotenv import load_dotenv\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import beta"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "llm = ChatOpenAI(\n    model=\"gpt-4o-mini\",\n    temperature=0.0,\n    base_url=\"https://openai.vocareum.com/v1\",\n    api_key=os.getenv(\"VOCAREUM_OPENAI_API_KEY\")\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tool creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "@tool\ndef plot_beta_distribution(alpha: float, beta_param: float, n_points: int = 1000):\n    \"\"\"\n    Plots the Beta distribution for given alpha and beta parameters.\n    \n    Args:\n        alpha (float): Shape parameter α (> 0)\n        beta_param (float): Shape parameter β (> 0)\n        n_points (int): Number of points in the x-axis grid\n    \"\"\"\n    # Create x values between 0 and 1\n    x = np.linspace(0, 1, n_points)\n    \n    # Compute the Beta PDF for each x\n    y = beta.pdf(x, alpha, beta_param)\n    \n    # Plot\n    plt.figure(figsize=(8, 4))\n    plt.plot(x, y, 'b-', lw=2, label=f'Beta(α={alpha}, β={beta_param})')\n    plt.title(\"Beta Distribution\", fontsize=14)\n    plt.xlabel(\"x\", fontsize=12)\n    plt.ylabel(\"Density\", fontsize=12)\n    plt.legend()\n    plt.grid(alpha=0.3)\n    plt.show()\n    \n    return f\"Plotted Beta distribution with α={alpha}, β={beta_param}\""
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [multiply, plot_beta_distribution]\n",
    "tool_map = {tool.name:tool for tool in tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multiply': StructuredTool(name='multiply', description='Multiply two numbers.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x11bc1f9c0>),\n",
       " 'plot_beta_distribution': StructuredTool(name='plot_beta_distribution', description='Plots the Beta distribution for given alpha and beta parameters.\\n\\nArgs:\\n    alpha (float): Shape parameter α (> 0)\\n    beta_param (float): Shape parameter β (> 0)\\n    n_points (int): Number of points in the x-axis grid', args_schema=<class 'langchain_core.utils.pydantic.plot_beta_distribution'>, func=<function plot_beta_distribution at 0x11bc072e0>)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binding Tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools, tool_choice=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what does a beta distribution look like with alpha=2 and beta=5?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what does a beta distribution look like with alpha=2 and beta=5?\n"
     ]
    }
   ],
   "source": [
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"You're a helpful assistant. ALWAYS use the tools provided to you. NEVER calculate the answer yourself.\"),\n",
    "    HumanMessage(question)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message = llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot_beta_distribution {'alpha': 2, 'beta_param': 5}\n",
      "{'refusal': None}\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Use tool_calls attribute directly (preferred)\n",
    "if ai_message.tool_calls:\n",
    "    for tool_call in ai_message.tool_calls:\n",
    "        # tool_call is already parsed!\n",
    "        function_name = tool_call['name']\n",
    "        arguments = tool_call['args']\n",
    "        print(function_name, arguments)\n",
    "        print(ai_message.additional_kwargs)\n",
    "else:\n",
    "    print(f\"No tool calls. Answer: {ai_message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('content', '')\n",
      "('additional_kwargs', {'refusal': None})\n",
      "('response_metadata', {'token_usage': {'completion_tokens': 20, 'prompt_tokens': 163, 'total_tokens': 183, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CaoUhljvWpqsUg59cD4UsgrtsS2mr', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None})\n",
      "('type', 'ai')\n",
      "('name', None)\n",
      "('id', 'lc_run--0bbccafe-414a-44ed-b5a9-394089ace232-0')\n",
      "('tool_calls', [{'name': 'plot_beta_distribution', 'args': {'alpha': 2, 'beta_param': 5}, 'id': 'call_j9ir6kphn7qHEkeRNXhRntvl', 'type': 'tool_call'}])\n",
      "('invalid_tool_calls', [])\n",
      "('usage_metadata', {'input_tokens': 163, 'output_tokens': 20, 'total_tokens': 183, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n"
     ]
    }
   ],
   "source": [
    "for a in ai_message:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 163, 'total_tokens': 183, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CaoUhljvWpqsUg59cD4UsgrtsS2mr', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--0bbccafe-414a-44ed-b5a9-394089ace232-0', tool_calls=[{'name': 'plot_beta_distribution', 'args': {'alpha': 2, 'beta_param': 5}, 'id': 'call_j9ir6kphn7qHEkeRNXhRntvl', 'type': 'tool_call'}], usage_metadata={'input_tokens': 163, 'output_tokens': 20, 'total_tokens': 183, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You're a helpful assistant. ALWAYS use the tools provided to you. NEVER calculate the answer yourself.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what does a beta distribution look like with alpha=2 and beta=5?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 163, 'total_tokens': 183, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CaoUhljvWpqsUg59cD4UsgrtsS2mr', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--0bbccafe-414a-44ed-b5a9-394089ace232-0', tool_calls=[{'name': 'plot_beta_distribution', 'args': {'alpha': 2, 'beta_param': 5}, 'id': 'call_j9ir6kphn7qHEkeRNXhRntvl', 'type': 'tool_call'}], usage_metadata={'input_tokens': 163, 'output_tokens': 20, 'total_tokens': 183, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"You're a helpful assistant. ALWAYS use the tools provided to you. NEVER calculate the answer yourself.\" additional_kwargs={} response_metadata={}\n",
      "content='what does a beta distribution look like with alpha=2 and beta=5?' additional_kwargs={} response_metadata={}\n",
      "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 163, 'total_tokens': 183, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CaoUhljvWpqsUg59cD4UsgrtsS2mr', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--0bbccafe-414a-44ed-b5a9-394089ace232-0' tool_calls=[{'name': 'plot_beta_distribution', 'args': {'alpha': 2, 'beta_param': 5}, 'id': 'call_j9ir6kphn7qHEkeRNXhRntvl', 'type': 'tool_call'}] usage_metadata={'input_tokens': 163, 'output_tokens': 20, 'total_tokens': 183, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "for m in messages:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Tool Calls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Use tool_calls directly - they're already parsed!\nif ai_message.tool_calls:\n    parsed_tool_calls = ai_message.tool_calls\n    print(f\"Found {len(parsed_tool_calls)} tool call(s)\")\nelse:\n    parsed_tool_calls = []\n    print(\"No tool calls found\")"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parsed_tool_calls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mparsed_tool_calls\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'parsed_tool_calls' is not defined"
     ]
    }
   ],
   "source": [
    "parsed_tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "for tool_call in parsed_tool_calls:\n    tool_call_id = tool_call['id']\n    function_name = tool_call['name']\n    arguments = tool_call['args']\n    \n    print(f\"Executing: {function_name}({arguments})\")\n    \n    func = tool_map[function_name]\n    result = func.invoke(arguments)\n    \n    # Convert result to string if needed\n    result_str = str(result)\n    \n    tool_message = ToolMessage(\n        content=result_str,\n        name=function_name,\n        tool_call_id=tool_call_id,\n    )\n    messages.append(tool_message)\n    \nprint(f\"Executed {len(parsed_tool_calls)} tool(s)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sending the result back to the LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You're a helpful assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what does a beta distribution look like with alpha=2 and beta=5?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 149, 'total_tokens': 169, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CaoSIGh2rT2P8twLi54FovjzvOV8R', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--3e280dc7-983e-41fc-8bc4-db0d432ae628-0', tool_calls=[{'name': 'plot_beta_distribution', 'args': {'alpha': 2, 'beta_param': 5}, 'id': 'call_pfjViHWIX7uDvA7BSWAkfHyU', 'type': 'tool_call'}], usage_metadata={'input_tokens': 149, 'output_tokens': 20, 'total_tokens': 169, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Send messages back to LLM to get final formatted response\nfinal_response = llm_with_tools.invoke(messages)\nprint(\"Final Response:\")\nprint(final_response.content)"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 149, 'total_tokens': 169, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CaoSIGh2rT2P8twLi54FovjzvOV8R', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--3e280dc7-983e-41fc-8bc4-db0d432ae628-0', tool_calls=[{'name': 'plot_beta_distribution', 'args': {'alpha': 2, 'beta_param': 5}, 'id': 'call_pfjViHWIX7uDvA7BSWAkfHyU', 'type': 'tool_call'}], usage_metadata={'input_tokens': 149, 'output_tokens': 20, 'total_tokens': 169, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 145, 'total_tokens': 165, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CaoTOdB9cgAz1BWlzhevE2PHH3OtP', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--166ab1f5-3287-4042-a225-0820b944b7f5-0' tool_calls=[{'name': 'plot_beta_distribution', 'args': {'alpha': 2, 'beta_param': 5}, 'id': 'call_IMjECwvWVDox7UyCHJu30SHB', 'type': 'tool_call'}] usage_metadata={'input_tokens': 145, 'output_tokens': 20, 'total_tokens': 165, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "question = \"Plot the Beta distribution for alpha=2 and beta=5\"\n",
    "messages = [\n",
    "    SystemMessage(\"You're a helpful assistant\"),\n",
    "    HumanMessage(question)\n",
    "]\n",
    "\n",
    "ai_message = llm_with_tools.invoke(messages)\n",
    "print(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'refusal': None}\n"
     ]
    }
   ],
   "source": [
    "print(ai_message.additional_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}